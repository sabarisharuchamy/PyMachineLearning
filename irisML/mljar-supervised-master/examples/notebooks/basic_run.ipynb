{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openml\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from supervised.automl import AutoML\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.model_selection\n",
    "from sklearn.metrics import log_loss, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = 3\n",
    "df = pd.read_csv('../../tests/data/{0}.csv'.format(dataset_id))\n",
    "x_cols = [c for c in df.columns if c != 'target']\n",
    "X = df[x_cols]\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      bkblk  bknwy  bkon8  bkona  bkspr  bkxbq  bkxcr  bkxwp  blxwp  bxqsq  \\\n",
      "0       1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0   \n",
      "1       1.0    1.0    1.0    1.0    0.0    1.0    1.0    1.0    1.0    1.0   \n",
      "2       1.0    1.0    1.0    1.0    0.0    1.0    0.0    1.0    1.0    1.0   \n",
      "3       1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    0.0    1.0   \n",
      "4       1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "3191    0.0    1.0    1.0    1.0    1.0    1.0    0.0    1.0    1.0    1.0   \n",
      "3192    0.0    1.0    1.0    1.0    1.0    1.0    0.0    1.0    1.0    1.0   \n",
      "3193    0.0    1.0    1.0    1.0    1.0    1.0    0.0    1.0    1.0    1.0   \n",
      "3194    0.0    1.0    0.0    1.0    1.0    1.0    0.0    1.0    1.0    1.0   \n",
      "3195    0.0    1.0    0.0    1.0    1.0    1.0    0.0    1.0    1.0    1.0   \n",
      "\n",
      "      ...  skrxp  spcop  stlmt  thrsk  wkcti  wkna8  wknck  wkovl  wkpos  \\\n",
      "0     ...    1.0    1.0    1.0    1.0    1.0    1.0    1.0    0.0    0.0   \n",
      "1     ...    1.0    1.0    1.0    1.0    1.0    1.0    1.0    0.0    0.0   \n",
      "2     ...    1.0    1.0    1.0    1.0    1.0    1.0    1.0    0.0    0.0   \n",
      "3     ...    1.0    1.0    1.0    1.0    1.0    1.0    1.0    0.0    0.0   \n",
      "4     ...    1.0    1.0    1.0    1.0    1.0    1.0    1.0    0.0    0.0   \n",
      "...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "3191  ...    1.0    1.0    0.0    1.0    1.0    0.0    1.0    0.0    1.0   \n",
      "3192  ...    1.0    1.0    0.0    1.0    1.0    0.0    1.0    0.0    1.0   \n",
      "3193  ...    1.0    1.0    0.0    1.0    1.0    0.0    1.0    0.0    1.0   \n",
      "3194  ...    1.0    1.0    0.0    1.0    1.0    0.0    1.0    1.0    1.0   \n",
      "3195  ...    1.0    1.0    0.0    1.0    1.0    0.0    1.0    1.0    1.0   \n",
      "\n",
      "      wtoeg  \n",
      "0       0.0  \n",
      "1       0.0  \n",
      "2       0.0  \n",
      "3       0.0  \n",
      "4       0.0  \n",
      "...     ...  \n",
      "3191    0.0  \n",
      "3192    0.0  \n",
      "3193    0.0  \n",
      "3194    0.0  \n",
      "3195    0.0  \n",
      "\n",
      "[3196 rows x 36 columns]\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "3191    1\n",
      "3192    1\n",
      "3193    1\n",
      "3194    1\n",
      "3195    1\n",
      "Name: target, Length: 3196, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = AutoML(total_time_limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: AutoML_1\n",
      "The task is binary_classification with evaluation metric logloss\n",
      "AutoML will use algorithms: ['Baseline', 'Linear', 'Decision Tree', 'Random Forest', 'Xgboost', 'Neural Network']\n",
      "AutoML will ensemble availabe models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default bandwidth for data is 0; skipping density estimation.\n",
      "Default bandwidth for data is 0; skipping density estimation.\n",
      "Default bandwidth for data is 0; skipping density estimation.\n",
      "Default bandwidth for data is 0; skipping density estimation.\n",
      "Default bandwidth for data is 0; skipping density estimation.\n",
      "Default bandwidth for data is 0; skipping density estimation.\n",
      "Default bandwidth for data is 0; skipping density estimation.\n",
      "Default bandwidth for data is 0; skipping density estimation.\n",
      "Default bandwidth for data is 0; skipping density estimation.\n",
      "Default bandwidth for data is 0; skipping density estimation.\n",
      "Default bandwidth for data is 0; skipping density estimation.\n",
      "Default bandwidth for data is 0; skipping density estimation.\n",
      "Default bandwidth for data is 0; skipping density estimation.\n",
      "Default bandwidth for data is 0; skipping density estimation.\n",
      "Default bandwidth for data is 0; skipping density estimation.\n",
      "Default bandwidth for data is 0; skipping density estimation.\n",
      "Default bandwidth for data is 0; skipping density estimation.\n",
      "Default bandwidth for data is 0; skipping density estimation.\n",
      "Default bandwidth for data is 0; skipping density estimation.\n",
      "Default bandwidth for data is 0; skipping density estimation.\n",
      "Default bandwidth for data is 0; skipping density estimation.\n",
      "Default bandwidth for data is 0; skipping density estimation.\n",
      "Default bandwidth for data is 0; skipping density estimation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'ensemble']\n",
      "* Step simple_algorithms will try to check up to 3 models\n",
      "1_Baseline logloss 0.692188 trained in 0.46 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-29 08:22:31,045 concurrent.futures ERROR exception calling callback for <Future at 0x1beb75664c0 state=finished raised BrokenProcessPool>\n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "'''\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 391, in _process_worker\n",
      "    call_item = call_queue.get(block=True, timeout=timeout)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\queues.py\", line 116, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\supervised\\__init__.py\", line 3, in <module>\n",
      "    from supervised.automl import AutoML\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\supervised\\automl.py\", line 3, in <module>\n",
      "    from supervised.base_automl import BaseAutoML\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\supervised\\base_automl.py\", line 17, in <module>\n",
      "    from supervised.algorithms.registry import AlgorithmsRegistry\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\supervised\\algorithms\\registry.py\", line 69, in <module>\n",
      "    import supervised.algorithms.catboost\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\supervised\\algorithms\\catboost.py\", line 20, in <module>\n",
      "    from catboost import CatBoostClassifier, CatBoostRegressor, CatBoost\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\catboost\\__init__.py\", line 1, in <module>\n",
      "    from .core import FeaturesData, EFstrType, Pool, CatBoost, CatBoostClassifier, CatBoostRegressor, CatBoostError, cv, train, sum_models, _have_equal_features, to_regressor, to_classifier, MultiRegressionCustomMetric, MultiRegressionCustomObjective  # noqa\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\catboost\\core.py\", line 42, in <module>\n",
      "    from . import _catboost\n",
      "ImportError: DLL load failed while importing _catboost: The paging file is too small for this operation to complete.\n",
      "'''\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 340, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 769, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 551, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\reusable_executor.py\", line 159, in submit\n",
      "    return super(_ReusablePoolExecutor, self).submit(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 1027, in submit\n",
      "    raise self._flags.broken\n",
      "joblib.externals.loky.process_executor.BrokenProcessPool: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem during computing permutation importance. Skipping ...\n",
      "2_DecisionTree logloss 0.250825 trained in 23.4 seconds\n",
      "Skip default_algorithms because of the time limit.\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble logloss 0.250825 trained in 0.31 seconds\n",
      "AutoML fit time: 32.03 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoML(total_time_limit=10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
